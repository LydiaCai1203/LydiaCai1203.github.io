<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 on Hugo Cactus Theme</title>
    <link>https://lydiacai1203.github.io/categories/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on Hugo Cactus Theme</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 07 Aug 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://lydiacai1203.github.io/categories/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>聚类算法原理</title>
      <link>https://lydiacai1203.github.io/post/clustering_algorithm/</link>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://lydiacai1203.github.io/post/clustering_algorithm/</guid>
      <description>1. K-means（EM 算法） 1. 概念 存储用于定义聚类的 K 个质心。点离哪个质心最近，就被认为属于哪个类; K-means 通过交替进行以下两步找到质心： 1) 根据当前质心划分数据点; 2) 根据当前数据点计算聚类的质心; 2. 算法详解 1) 初始化质心，通常会随机选择 K 个数据点 2) 将每个点归类，离哪个质心最近，就属于哪一类 3) 计算当前簇类的平均值，找到新的质心 4) 重复 2、3 步 3. WCSS(Within-Cluster-Sum-Of-Squares) 每一个数据点到其所属质心的距离的平方和，就是 WCSS。 4. Elbow Curve x 轴就是 K 值，y 轴就是 WCSS, 画出曲线。将其中下降剧烈的点称为肘点，肘点对应的 K 值就是最佳 K 值。 5. 优点 1) 适合高斯分布数据集 2) 适合同质数据 3) 适合聚类之间界限清晰，不重叠的情况 4) 适合中等大小的数据集 6. 缺点 1) 不适合复杂分布的数据集 2) 需要提前预设 K 值，最优解查找不佳 3) 不适合大数据集，计算成本高昂 4) 对初始中心敏感，容易受到数据中的噪声和异常值的影响 5) 对噪声和异常值敏感 7.</description>
    </item>
    <item>
      <title>FastAPI Depend 实现原理(个人猜测&#43;粗略代码实现)</title>
      <link>https://lydiacai1203.github.io/post/fastapi_depend/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://lydiacai1203.github.io/post/fastapi_depend/</guid>
      <description>0. 依赖注入 from fastapi import Depends, FastAPI, HTTPException from sqlalchemy.orm import Session from . import crud, models, schemas from .database import SessionLocal, engine models.Base.metadata.create_all(bind=engine) app = FastAPI() # Dependency def get_db(): db = SessionLocal() try: yield db finally: db.close() @app.post(&amp;#34;/users/&amp;#34;, response_model=schemas.User) def create_user(user: schemas.UserCreate, db: Session = Depends(get_db)): pass 1. 猜测原理 线索 1. 依赖注入的参数是作为参数从函数传入的，因此排除装饰器实现 2. 表现行为是 handler 开始执行前 db 被实例化好, handler 结束后 db 被 close；表现类似 contextmanager 3. 不结合装饰器 @app.post 使用，发现 db 无法倍正确实例化，而是一个 Depend 类的对象 结论 1.</description>
    </item>
    <item>
      <title>安全开发指南（持续更新）</title>
      <link>https://lydiacai1203.github.io/post/sec_guide/</link>
      <pubDate>Sat, 09 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://lydiacai1203.github.io/post/sec_guide/</guid>
      <description>开发规范&#xA;腾讯 Python 安全指南&#xA;1. 代码实现 1. 避免使用不安全的对称加密算法（避免 DES/3DES，建议 AES） 2. 确保重要行为都记录在日志上，且可靠保存 6 个月以上 3. 禁止将未经验证的用户输入直接记录日志（防止注入漏洞：恶意用户插入伪造的日志数据，从而让系统管理员以为是系统行为） 4. 避免在日志中保存敏感信息（明文密码、密文密码 等等） 2. 系统口令 1. 禁止使用 空口令、弱口令、已泄漏口令 2. 口令强度需满足 + 密码长度大于 14 位 + 包含：大小写英文字母、数字、特殊字符 + 不得使用默认的初始密码 + 不能与最近 6 次使用过的密码重复 + 不得与其它外部系统使用相同的密码 3. 口令存储安全 + 禁止明文存储口令 + 禁止使用弱密码学算法加密存储口令 + 使用 不可逆算法 和 随机 salt 对口令进行加密存储 + 禁止传递明文口令 + 禁止在不安全的信道中传输口令 3. 配置 / 环境 1. 建议使用 Python 3.6+ 版本，因为 Python3 在 2020 年就停止维护了，相关漏洞不能得到及时修复和维护 2.</description>
    </item>
    <item>
      <title>Python 原生 SQL 如何预防 SQL 注入</title>
      <link>https://lydiacai1203.github.io/post/raw_sql_q/</link>
      <pubDate>Fri, 08 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://lydiacai1203.github.io/post/raw_sql_q/</guid>
      <description>什么是 SQL 注入 腾讯云博客 SQL 注入攻击是一种常见的Web攻击方法，攻击者通过把 SQL 命令注入到 Web 后台数据库的查询字符串中，最终达到欺骗服务器执行恶意 SQL 命令的目的。例如可以从数据库获取敏感信息，或者利用数据库的特性执行添加用户、导出文件等一系列恶意操作，甚至有可能获取数据库乃至系统用户最高权限。 2. SQL 注入例子 SQL 注入只会发生在字符串拼接的例子中，常见的攻击有拖库、拖表、篡改网页内容、收集数据库信息为其它攻击做准备等等。&#xA;假设代码中是这样一段代码 username = input(&amp;ldquo;enter in username&amp;rdquo;) sql = f&amp;quot;&amp;quot;&amp;quot; select * from content where create_user = &amp;ldquo;{username}&amp;rdquo; &amp;quot;&amp;quot;&amp;quot;&#xA;用户输入 username = &amp;rsquo;testc&amp;quot; or 1 = &amp;ldquo;1&amp;rsquo;, SQL 就会变成 sql = f&amp;rdquo;&amp;quot;&amp;quot; select * from content where create_user = &amp;ldquo;testc&amp;rdquo; or 1 = &amp;ldquo;1&amp;rdquo; &amp;quot;&amp;quot;&amp;quot; 3. SQL 注入预防通用方法&#xA;外部参数动态拼接 [&amp;quot;\&amp;quot;&amp;quot;, &amp;quot;\\&amp;quot;, &amp;quot;/&amp;quot;, &amp;quot;*&amp;quot;, &amp;quot;&#39;&amp;quot;, &amp;quot;=&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;#&amp;quot;, &amp;quot;;&amp;quot;, &amp;quot;&amp;lt;&amp;quot;, &amp;quot;&amp;gt;&amp;quot;, &amp;quot;+&amp;quot;, &amp;quot;&amp;amp;&amp;quot;, &amp;quot;$&amp;quot;, &amp;quot;(&amp;quot;, &amp;quot;)&amp;quot;, &amp;quot;%&amp;quot;, &amp;quot;@&amp;quot;, &amp;quot;,&amp;quot;] 过滤特殊符号 遇到固定格式的变量，在 SQL 执行前严格按照固定格式检查 特殊符号转义使用（SQL 中的转义字符是单引号） 参数化查询 绑定变量使用预编译语句（预防 SQL 注入的最佳方式） ORM 使用 ORM 避免 SQL 注入 存储 敏感信息加密存储 将 username = &amp;rsquo;testc&amp;quot; or 1 = &amp;ldquo;1&amp;rsquo; 中的特殊符号转译，除了左右两侧的单引号 这样 &amp;ldquo;testc&amp;rsquo;&amp;rdquo; or 1 = &amp;lsquo;&amp;ldquo;1&amp;rdquo; 就变成了一个值，而非表达式的一部分 sql = f&amp;rdquo;&amp;quot;&amp;quot; select * from content where create_user = &amp;ldquo;testc&amp;rsquo;&amp;rdquo; or 1 = &amp;lsquo;&amp;ldquo;1&amp;rdquo; &amp;quot;&amp;quot;&amp;quot; 4.</description>
    </item>
    <item>
      <title>Linux lsof 命令使用</title>
      <link>https://lydiacai1203.github.io/post/linux_lsof_usage/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://lydiacai1203.github.io/post/linux_lsof_usage/</guid>
      <description>为了以后查阅方便所做。 ------- 菜大头 lsof 简介 `lsof` 是 `list open files` 的简称。意思是 列出系统中打开的文件。由于 Linux 中 `everything is file`。所有的对象都可以看作是文件，`lsof` 就可以知道用户和进程都操作了哪些文件，也可以查看系统中网络的使用情况、设备信息。 lsof | head -n 20 会列出系统中所有打开的前20个文件，每个文件一行 FD cwd: 当前工作目录 txt: 应用文本(代码、数据) mem: 内存映射文件 mmap: 内存映射设备 TYPE REG: 普通文件 DIR: 文件夹 lsof -p 1190 打开 1190 进程打开的所有文件 lsof -u caiqingjing or lsof -u ^caiqingjing 打开某个用户打开的文件 or 除了某个用户.. lsof file_path 查看某个 文件/目录 被哪些进程打开 lsof +d dir_path 列出访问某个目录的所有进程 lsof -c nginx 列出某个命令使用的文件信息 使用 lsof 查看网络信息 lsof -i 列出所有的网络连接信息 lsof -i TCP -i 后面跟协议类型，只显示 TCP 网络协议的连接信息 lsof -i :80 查看 80 端口被哪个进程使用 lsof -i @172.</description>
    </item>
    <item>
      <title>Linux 内存管理</title>
      <link>https://lydiacai1203.github.io/post/linux_memory_manage/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://lydiacai1203.github.io/post/linux_memory_manage/</guid>
      <description>free usage (venv367) caiqingjing@ip-127.0.0.1:~$ free -h 总计 已用 空闲 共享 缓冲/缓存 可用 内存： 31G 7.1G 2.7G 105M 21G 23G交换： 0B 0B 0B 1. 关注 可用 列，估计有多少内存可用于启动新的程序而无须交换。 2. 理论上，used - buffers/cache 表示应用程序实际使用的内存？；free+buffers/cache 表示理论上可以被使用的内存。free 仅仅表示未被使用的内存大小。仅仅看 free 来判断是不够准确的。 3. 当可用内存接近 0 或 非常小时，已用内存接近总容量 时，意味这需要使用到交换磁盘了。可以使用 `grep -i kill /var/log/messages *` 或 `dmesg | grep oom-killer` 检查内存溢出日志消息。 缓存（cache） read_cache:读文件时，通常需要将硬盘里的数据读入内存，但是硬盘和内存的读取速度相差太多，因此 linux 会将数据读入 cache 中，然后从 cache 中读取需要的数据。当一个缓存中的数据被多次读取，实际上就减少了该数据从慢速设备中读取的次数。因此 cache 中的数据是随机访问的特性。write_cache:与 read_cache 对应，它的目标应该是减少写入慢速设备的次数。使用 cache 的话，可以多次写入 cache, 但是只写入一次硬盘。 缓冲（buffer） read_buffer: 每当 buffer 满或者主动 `flush` 时会触发一次读取，对于小数据可以减少读取次数，对于大数据可以控制单次读取的数据量。通常来说，先入 buffer 的数据会被先读取，所有的 buffer 数据几乎一定会被读取，拥有顺序访问的特性。write_buffer:同上，也是需要 buffer 满或者主动 `flush` 时才会触发写入。如果每次写入的数据量相对固定。因为如果一次写入 4k 对与某个设备来说效率最高的话，buffer 一定是 4k。小数据积攒到 4k 写入，大数据分割成 4k 的碎片写入，这是 write_buffer 的用处。 交换内存（swapping） 当主存(RAM) 不足以临时存储多个程序时，我们从 RAM 中取出一些程序，通过 swap out 的机制将它们存储到硬盘中。当 RAM 可用时，我们再次将程序从硬盘交换到 RAM, 这就是 swap in。Linux 中的交换空间是物理内存的两倍。优点： 1.</description>
    </item>
    <item>
      <title>断点续传的原理</title>
      <link>https://lydiacai1203.github.io/post/download_file/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://lydiacai1203.github.io/post/download_file/</guid>
      <description>参考文档&#xA;1. 什么是断点续传？ 可以让用户从上一次下载中断的位置接着下载的机制。 2. 断点续传的原理 1. `curl -I {url}` 查看响应头部是否有 `content-range` 字样，有则代表服务端支持断点续传功能。 2. HTTP HEADERS 1.1 Range(在有 If-Range 的时候才会生效) * Range: bytes=0-1023 请求资源的前 1024 个字节 * Range: bytes=-1023 请求资源的倒数 1023 个字节 * Range: bytes=1023- 请求资源第 1024 字节开始及以后的资源 * Range: bytes=0-50, 100-150 请求资源的多个部分 1.2 If-Range(必传两个中的一个，但不能同时传) 1.2.1 Etag * 675af34563dc-tr34 * 文件资源的唯一标示，一个字符串 1.2.2 Last-Modified * If-Range: Wed, 21 Oct 2015 07:28:00 GMT * 上一次文件资源修改时间 3. RESP HTTP STATUS CODE 3.1 206 - Partial Content（此次请求成功） 3.</description>
    </item>
    <item>
      <title>Elasticsearch2.x 权威文档 （摘抄）</title>
      <link>https://lydiacai1203.github.io/post/es_doc_readingnote/</link>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://lydiacai1203.github.io/post/es_doc_readingnote/</guid>
      <description>Elasticsearch2.x 权威文档 （摘抄） 很多用法都已经过时，看完这个我打算再看一下 7.x。仅作为快速查阅的工具文档使用，可能不会和原文一致。希望尽量做到精简。 有一些模块因为暂时使用不到所以选择不看，毕竟没有应用的情况下是很容易忘记的。&#xA;1. 面向文档 Elasticsearch 是 面向文档 的，意味着它存储整个对象或文档，Elasticsearch 不仅存储文档，而且 索引 每个文档的内容，使之可以被检索。在 Elasticsearch 中，我们对文档(而不是对行列数据)进行索引、检索、排序、过滤，这也是 Elasticsearch 能支持复杂全文检索的原因。&#xA;2. JSON Elasticsearch 使用 JavaScript Object Notation (JSON) 作为文档的序列化格式。具体可以看 serialization 和 marshalling 两个处理模块。&#xA;3. 几个名词 索引 .n 一个索引类似于一个数据库，是一个存储文档的地方。 索引 .v 索引一个文档就是存储一个文档到一个索引中以便于被检索或是被查询。类似于 insert, 当文档已存在时(_id已有) 会进行更新。 倒排索引 倒排索引被作用在文档上，以便于提升数据的检索速度。默认的，文档中的每一列都有倒排索引，没有倒排索引的属性是不可能被搜索到的。 4. 检索文档 GET - /index/mapping/id 即可检索出 ID 对应的对象&#xA;GET - /index/mapping/_search 用于检索所有的对象(一个搜索默认返回十条结果, 放在 hits 中)&#xA;GET - /index/mapping/_search?q=alst_name:Smith – URL 查询参数查询&#xA;GET - /index/mapping/_search – 进行查询表达式搜索(部分匹配)</description>
    </item>
    <item>
      <title>GIT 常用命令查阅手册</title>
      <link>https://lydiacai1203.github.io/post/git_command/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://lydiacai1203.github.io/post/git_command/</guid>
      <description>练习平台 - 强烈建议新手通关&#xA;git commit 将当前版本和仓库的上一版本进行对比，将所有的差异打包到一起作为一个提交记录。 git branch &amp;lt;branch_name&amp;gt; 创建分支 git merge &amp;lt;branch_name&amp;gt; git rebase master 将 bugFix 里面的 commit 按照顺序复制到 master 下。也就是说 bugFix 在 master 分支的最顶端了。 git checkout master git rebase bugFix # 相当于将 master 的 commit 复制到 fixBug 下，master 会在 bugFix 的顶端，所以 master 只会往下移一格。 HEAD 总是指向当前分支上最近一次的提交记录。 HEAD 通常情况下指向分支名的。 也就是说 master 分支其实是 master 指针，head 指针是单独的 head 指针。 `git checkout &amp;lt;commit-sha&amp;gt;` 便可以移动 head 指针。 cat .git/HEAD git symbolic-ref HEAD 这两句可以查看当前的 HEAD 指针指向 ^ 相对引用，n 个 ^ 或者 ~n 就是向上 n 个 commit git checkout master^ 或者 git checkout HEAD~4 git branch -f master HEAD~3 强制修改分支位置，将 master 分支强制指向 HEAD 的第三个父级提交。 git reset HEAD~1 通过分支记录回退几个提交记录来实现撤销改动。 git revert HEAD 通过在要撤销的提交记录后面新增一个提交，然后在新提交里面引入一些更改，这些更改便是用于撤销记录的。 git cherry-pick 将一些提交复制到 HEAD 下。 交互式的 rebase 如果你不知道要提交的 sha 值，就可以使用交互式的 rebase.</description>
    </item>
    <item>
      <title>Study Tips(2019&#43;2020)</title>
      <link>https://lydiacai1203.github.io/post/study_tips_2019/</link>
      <pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://lydiacai1203.github.io/post/study_tips_2019/</guid>
      <description>1.10:57 完成了人生中第一次服务器购买以及成功地翻出了墙.&#xA;2.解决了一个关于使用gunicorn打印不出日志的问题&#xA;3.破解了银保监的反爬，学到很多东西&#xA;4.将html转成pdf的简便方法，用chrome打开html，ctrl+p就可以转化成pdf了&#xA;5.mongodb创建联合索引create_index([(field, 1), (field2, -1)])&#xA;6.原来除了有os.system()直接执行command,还有os.popen()，原理是创建一个管道，然后可以这个管道里标准输出流里的东西拿出来，拿到return的对象，fp.read()即可，用完fp.close()&#xA;7.遇到了一个坑，使用phantomjs的时候，比较慢，所以我希望这玩意只有一个，就弄成了全局变量，结果，发现driver.quit()失效了，根本没关闭上，这就很恶心人了。 解决方法是弄成局部变量&#xA;8.假如问你：cookie和session的区别 你知道怎么回答吗 反正我是重新认识了cookie,而且最让我惊讶的是，问了好多同事，给我的回答竟然都是和我面试的时候是一样的回答。我有时候不禁会想，面试官在问我这个问题之前，自己是否也清楚cookie和session的区别呢&amp;hellip;..又放肆了，还是好好学习吧&#xA;9.markdown里面如果想使用空行的话，可以使用html里面的br标签，但是要在br标签的前后都给到一个空行，在github上面显示才比较好看。或者使用空格+空格+换行，也可以达到一样的效果&#xA;10.mysql5.6 的 最左前缀优先 和 mysql5.7 的 最左前缀优先不一样，比如说现在有一个联合索引(name, cid), 有一条查询语句：select * from tablename where cid=1;这条语句在5.6中就不会走索引，但是在5.7中会走索引&#xA;11.今天知道一个新的markdown语法，[TOC] 可以自动按照生成目录，但是github不支持&#xA;12.set里面允许放的是不可变对象, 什么是不可变对象(string, numbers, boolean), 同理dict的key也是。这个fluent-py里面有讲解。加入我现在有两堆对象，我想做一个交集。但是我不想用for循环一个一个去比对。这个对象的数据成员都是由基本类型组成的。对象显然是放不进set里面的，这时候只需要实现__hash__和__eq__，具体解释就不在这里写了，但是，但是，但是，你想要去比对，肯定是和__eq__有关系，所以在实现__eq__的时候，势必要结合具体的业务情况。这时候就可以愉快地做交集并集了。&#xA;13.之前研究了网页编码，一开始都是采用了resp.text，后来发现其实requests底层使用的是resp.encoding, 这个encoding的默认值取的是response.headers里的content-type中charset这个值，如果没有这个值呢，requests就会使用chardet进行编码判断(也就是get_encoding_from_headers)后来发现这个方法呢，其实并不好用，取出来的是个ISO-8859-1，这个东西解码字节数组以后也不对。又发现有一个get_encodings_from_content,这个是从html里面的meta里面取charset这个值。有些html会有多个meta标签，所以这个函数会取出多个charset，也就是一个列表。这个就要自己取取舍了。一般我认为如果是ISO-8859-1的话，就是用UTF进行编码，如果gb打头，就是用gb18030进行编码。因为gb2312&amp;lt;\gbk&amp;lt;\gb18030。另外很多时候，会出现一种情况就是，明明charset是对的，但是使用decode(charset)的时候会报错。这是因为网页中含有一些这个编码不可以解析的字符，是什么原因我不知道，但是可以使用decode(charset, &#39;ignore&#39;)，只显示那些能编码的字符。&#xA;14.虽然之前也遇到过supervisor装好了以后出现各种问题，今天尤其仔细地看了一下解决的方法，记录一下&#xA;supervisord -c /etc/supervisor/supervisord.conf 报错：Unlinking stale socket /var/run/supervisor.sock find / -name supervisor.sock # 全盘搜索这个文件名 unlink /**/supervisor.sock supervisord -c /etc/supervisor/supervisord.conf # 再重启supervisord服务 15.Python设计和历史常见问题&#xA;16.一个可以拿到访问者ip的接口&#xA;17.what-cicd&#xA;18.一些好用的网站？&#xA;在线ps&#xA;周读&#xA;临时邮箱&#xA;工具网</description>
    </item>
  </channel>
</rss>
